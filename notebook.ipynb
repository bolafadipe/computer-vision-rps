{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock\n"
     ]
    }
   ],
   "source": [
    "np.array(prediction)\n",
    "idx_max = prediction.argmax()\n",
    "choices = [\"rock\", \"paper\", \"scissors\", \"nothing\"]\n",
    "print(choices[idx_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "my_list = [[0.1,0.8,0.05,0.05]]\n",
    "max_val = max(my_list[0])\n",
    "idx_max = my_list[0].index(max_val)\n",
    "choices = [\"rock\", \"paper\", \"scissors\", \"nothing\"]\n",
    "print(choices[idx_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "2\n",
      "scissors\n"
     ]
    }
   ],
   "source": [
    "prediction = [[0.1,0.2,0.9,0.05]]\n",
    "max_val = max(prediction[0])\n",
    "print(max_val)\n",
    "idx_max = prediction[0].index(max_val)\n",
    "print(idx_max)\n",
    "choices = [\"rock\", \"paper\", \"scissors\", \"nothing\"]\n",
    "print(choices[idx_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[9.9996674e-01 3.1360076e-05 7.0703003e-08 1.7979771e-06]]\n",
      "passing\n",
      "1. stopped camera\n",
      "[[9.9996674e-01 3.1360076e-05 7.0703003e-08 1.7979771e-06]]\n",
      "2. cv_choice var prints: rock\n",
      "3. You picked: rock. The computer picked rock\n",
      "It's a draw!\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[9.9944836e-01 5.5166020e-04 1.7203015e-10 2.7640686e-08]]\n",
      "passing\n",
      "1. stopped camera\n",
      "[[9.9944836e-01 5.5166020e-04 1.7203015e-10 2.7640686e-08]]\n",
      "2. cv_choice var prints: rock\n",
      "3. You picked: rock. The computer picked rock\n",
      "It's a draw!\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[9.9997950e-01 1.9902533e-05 4.1473690e-08 6.3193073e-07]]\n",
      "passing\n",
      "1. stopped camera\n",
      "[[9.9997950e-01 1.9902533e-05 4.1473690e-08 6.3193073e-07]]\n",
      "2. cv_choice var prints: rock\n",
      "3. You picked: rock. The computer picked rock\n",
      "It's a draw!\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 917ms/step\n",
      "[[9.9998534e-01 1.4193496e-05 1.5602939e-08 4.8147530e-07]]\n",
      "game end\n"
     ]
    }
   ],
   "source": [
    "import random #for computer choice\n",
    "import cv2 #to leverage camera\n",
    "from keras.models import load_model #to run the  model\n",
    "import numpy as np #for arrays for interpretting the image\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class CvRps:\n",
    "\n",
    "    choice_list = ['rock', 'paper', 'scissors'] #declared this outside the init without self\n",
    "    start_time = time.time()\n",
    "\n",
    "    seconds = 3 #set how many seconds to run the camera \n",
    "    computer_wins = 0\n",
    "    user_wins = 0\n",
    "\n",
    "    def __init__(self,rounds):\n",
    "        self.rounds = 0 \n",
    "\n",
    "    def get_prediction(self, rounds):        \n",
    "        \n",
    "        \n",
    "        while self.rounds <= 3:\n",
    "            model = load_model('keras_model.h5')\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "            ret, frame = cap.read()\n",
    "            resized_frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            image_np = np.array(resized_frame)\n",
    "            normalized_image = (image_np.astype(np.float32) / 127.0) - 1 # Normalize the image\n",
    "            data[0] = normalized_image\n",
    "            cv2.imshow('frame', frame)\n",
    "            prediction = model.predict(data)\n",
    "            print(prediction) #test to see if the values are changing - REMOVE\n",
    "    \n",
    "            self.rounds = self.rounds + 1\n",
    "\n",
    "            current_time = time.time()\n",
    "            elapsed_time = current_time - CvRps.start_time\n",
    "            if elapsed_time > CvRps.seconds:\n",
    "                if self.rounds <= 3:\n",
    "                    print('passing')\n",
    "                    pass \n",
    "                else: \n",
    "                    break\n",
    "\n",
    "            self.stop_camera(cap)#call the method to stop the camera\n",
    "            self.get_user_choice(prediction)#call the convert the array to a choice\n",
    "        \n",
    "        else: \n",
    "            print('hit the last else') \n",
    "                \n",
    "\n",
    "        \n",
    "    def stop_camera(self, cap):\n",
    "        print('1. stopped camera') #just a test - REMOVE \n",
    "        cap.release()# After the loop release the cap object\n",
    "        cv2.destroyAllWindows()# Destroy all the windows\n",
    "        pass   \n",
    "\n",
    "    def get_user_choice(self, prediction):\n",
    "        print(prediction)\n",
    "        np.array(prediction) #convert to array\n",
    "        idx_max = prediction.argmax() #find the max value\n",
    "        choices = [\"rock\", \"paper\", \"scissors\", \"nothing\"]\n",
    "        user_camera_choice = choices[idx_max]\n",
    "        print(f'2. cv_choice var prints: {user_camera_choice}') ##just a test - REMOVE\n",
    "        self.get_computer_choice(user_camera_choice) \n",
    "\n",
    "    def get_computer_choice(self,user_choice):\n",
    "        computer_choice = random.choice(CvRps.choice_list)\n",
    "        print(f\"3. You picked: {user_choice}. The computer picked {computer_choice}\") #just testing to see if it makes it here\n",
    "        self.get_winner(user_choice, computer_choice)\n",
    "\n",
    "    def get_winner(self, user_choice, computer_choice):\n",
    "        if computer_choice == user_choice:\n",
    "            print(\"It's a draw!\")\n",
    "        elif computer_choice == 'rock' and user_choice == 'scissors':\n",
    "            CvRps.computer_wins += 1\n",
    "            print('You lost')\n",
    "        elif computer_choice == 'rock' and user_choice == 'paper':\n",
    "            print('You Won')\n",
    "            CvRps.user_wins += 1\n",
    "        elif computer_choice == 'paper' and user_choice == 'rock':\n",
    "            print('You lost')\n",
    "            CvRps.computer_wins += 1\n",
    "        elif computer_choice == 'paper' and user_choice == 'scissors':\n",
    "            print('You won')\n",
    "            CvRps.user_wins += 1\n",
    "        elif computer_choice == 'scissors' and user_choice == 'rock':\n",
    "            print('You won')\n",
    "            CvRps.user_wins += 1\n",
    "        elif computer_choice == 'scissors' and user_choice == 'paper':\n",
    "            print('You lost')\n",
    "            CvRps.computer_wins += 1\n",
    "        else:\n",
    "            print('No Result: Seems to be an error somewhere')\n",
    "\n",
    "def play_rps():\n",
    "    game = CvRps(3)\n",
    "    game.get_prediction(3)\n",
    "    print('game end')\n",
    "    cv2.VideoCapture(0).release()# After the loop release the cap object\n",
    "    cv2.destroyAllWindows()# Destroy all the windows\n",
    "\n",
    "\n",
    "play_rps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Round: 1-------------\n",
      "user score: 0 ||| Computer score: 0\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "the array from the prediction is: [[0.05356555 0.02043165 0.88671833 0.03928454]]\n",
      "\n",
      "----------Round: 2-------------\n",
      "user score: 0 ||| Computer score: 0\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "the array from the prediction is: [[0.34405234 0.41415146 0.20065556 0.04114057]]\n",
      "\n",
      "----------Round: 3-------------\n",
      "user score: 0 ||| Computer score: 0\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "the array from the prediction is: [[0.6900617  0.0875589  0.19633086 0.02604858]]\n",
      "...camera now stopping\n",
      "...camera stopped\n",
      "...You chose rock\n",
      "...The computer chose paper\n",
      "...You picked: rock. The computer picked paper\n",
      "...checking result:\n",
      "********** You lost **********\n",
      "\n",
      "----------Round: 4-------------\n",
      "user score: 0 ||| Computer score: 1\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 1s 979ms/step\n",
      "the array from the prediction is: [[0.02767595 0.01426607 0.9249458  0.03311229]]\n",
      "...camera now stopping\n",
      "...camera stopped\n",
      "...You chose scissors\n",
      "...The computer chose paper\n",
      "...You picked: scissors. The computer picked paper\n",
      "...checking result:\n",
      "********** You won ********** \n",
      "\n",
      "----------Round: 5-------------\n",
      "user score: 1 ||| Computer score: 1\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "the array from the prediction is: [[0.02909312 0.01359555 0.92697835 0.03033295]]\n",
      "...camera now stopping\n",
      "...camera stopped\n",
      "...You chose scissors\n",
      "...The computer chose scissors\n",
      "...You picked: scissors. The computer picked scissors\n",
      "...checking result:\n",
      "********** It's a draw! **********\n",
      "\n",
      "----------Round: 6-------------\n",
      "user score: 1 ||| Computer score: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m     cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mrelease()\u001b[39m# After the loop release the cap object\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\u001b[39m# Destroy all the windows\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m play_rps()\n",
      "\u001b[1;32m/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb Cell 5\u001b[0m in \u001b[0;36mplay_rps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplay_rps\u001b[39m():\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     game \u001b[39m=\u001b[39m CvRps(\u001b[39m3\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m     game\u001b[39m.\u001b[39;49mget_prediction(\u001b[39m3\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mgame end\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m     \u001b[39mprint\u001b[39m()\n",
      "\u001b[1;32m/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb Cell 5\u001b[0m in \u001b[0;36mCvRps.get_prediction\u001b[0;34m(self, rounds)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m current_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muser score: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_wins\u001b[39m}\u001b[39;00m\u001b[39m ||| Computer score: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomputer_wins\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39;49m\u001b[39mkeras_model2.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ronan/Desktop/GitHub/computer-vision-rps/notebook.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mndarray(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m3\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/saving/save.py:215\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m h5py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    213\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFilepath looks like a hdf5 file but h5py is not available.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    214\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m filepath=\u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mreturn\u001b[39;00m hdf5_format\u001b[39m.\u001b[39;49mload_model_from_hdf5(\n\u001b[1;32m    216\u001b[0m         tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mGFile(filepath_str, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m), custom_objects,\n\u001b[1;32m    217\u001b[0m         \u001b[39mcompile\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m \u001b[39melif\u001b[39;00m h5py \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath, h5py\u001b[39m.\u001b[39mFile):\n\u001b[1;32m    219\u001b[0m   \u001b[39mreturn\u001b[39;00m hdf5_format\u001b[39m.\u001b[39mload_model_from_hdf5(filepath, custom_objects,\n\u001b[1;32m    220\u001b[0m                                           \u001b[39mcompile\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/saving/hdf5_format.py:186\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    184\u001b[0m   model_config \u001b[39m=\u001b[39m model_config\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    185\u001b[0m model_config \u001b[39m=\u001b[39m json_utils\u001b[39m.\u001b[39mdecode(model_config)\n\u001b[0;32m--> 186\u001b[0m model \u001b[39m=\u001b[39m model_config_lib\u001b[39m.\u001b[39;49mmodel_from_config(model_config,\n\u001b[1;32m    187\u001b[0m                                            custom_objects\u001b[39m=\u001b[39;49mcustom_objects)\n\u001b[1;32m    189\u001b[0m \u001b[39m# set weights\u001b[39;00m\n\u001b[1;32m    190\u001b[0m load_weights_from_hdf5_group(f[\u001b[39m'\u001b[39m\u001b[39mmodel_weights\u001b[39m\u001b[39m'\u001b[39m], model)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/saving/model_config.py:51\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`model_from_config` expects a dictionary, not a list. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     48\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReceived: config=\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m}\u001b[39;00m\u001b[39m. Did you meant to use \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     49\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m`Sequential.from_config(config)`?\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize  \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[39mreturn\u001b[39;00m deserialize(config, custom_objects\u001b[39m=\u001b[39;49mcustom_objects)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/layers/serialization.py:205\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m populate_deserializable_objects()\n\u001b[0;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m generic_utils\u001b[39m.\u001b[39;49mdeserialize_keras_object(\n\u001b[1;32m    206\u001b[0m     config,\n\u001b[1;32m    207\u001b[0m     module_objects\u001b[39m=\u001b[39;49mLOCAL\u001b[39m.\u001b[39;49mALL_OBJECTS,\n\u001b[1;32m    208\u001b[0m     custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    209\u001b[0m     printable_module_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlayer\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/utils/generic_utils.py:679\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    676\u001b[0m custom_objects \u001b[39m=\u001b[39m custom_objects \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcustom_objects\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m arg_spec\u001b[39m.\u001b[39margs:\n\u001b[0;32m--> 679\u001b[0m   deserialized_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[1;32m    680\u001b[0m       cls_config,\n\u001b[1;32m    681\u001b[0m       custom_objects\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m    682\u001b[0m           \u001b[39mlist\u001b[39;49m(_GLOBAL_CUSTOM_OBJECTS\u001b[39m.\u001b[39;49mitems()) \u001b[39m+\u001b[39;49m\n\u001b[1;32m    683\u001b[0m           \u001b[39mlist\u001b[39;49m(custom_objects\u001b[39m.\u001b[39;49mitems())))\n\u001b[1;32m    684\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m   \u001b[39mwith\u001b[39;00m CustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/sequential.py:437\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    435\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(name\u001b[39m=\u001b[39mname)\n\u001b[1;32m    436\u001b[0m \u001b[39mfor\u001b[39;00m layer_config \u001b[39min\u001b[39;00m layer_configs:\n\u001b[0;32m--> 437\u001b[0m   layer \u001b[39m=\u001b[39m layer_module\u001b[39m.\u001b[39;49mdeserialize(layer_config,\n\u001b[1;32m    438\u001b[0m                                    custom_objects\u001b[39m=\u001b[39;49mcustom_objects)\n\u001b[1;32m    439\u001b[0m   model\u001b[39m.\u001b[39madd(layer)\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39minputs \u001b[39mand\u001b[39;00m build_input_shape \u001b[39mand\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[39misinstance\u001b[39m(build_input_shape, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))):\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/layers/serialization.py:205\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m populate_deserializable_objects()\n\u001b[0;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m generic_utils\u001b[39m.\u001b[39;49mdeserialize_keras_object(\n\u001b[1;32m    206\u001b[0m     config,\n\u001b[1;32m    207\u001b[0m     module_objects\u001b[39m=\u001b[39;49mLOCAL\u001b[39m.\u001b[39;49mALL_OBJECTS,\n\u001b[1;32m    208\u001b[0m     custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    209\u001b[0m     printable_module_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlayer\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/utils/generic_utils.py:679\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    676\u001b[0m custom_objects \u001b[39m=\u001b[39m custom_objects \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcustom_objects\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m arg_spec\u001b[39m.\u001b[39margs:\n\u001b[0;32m--> 679\u001b[0m   deserialized_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[1;32m    680\u001b[0m       cls_config,\n\u001b[1;32m    681\u001b[0m       custom_objects\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m    682\u001b[0m           \u001b[39mlist\u001b[39;49m(_GLOBAL_CUSTOM_OBJECTS\u001b[39m.\u001b[39;49mitems()) \u001b[39m+\u001b[39;49m\n\u001b[1;32m    683\u001b[0m           \u001b[39mlist\u001b[39;49m(custom_objects\u001b[39m.\u001b[39;49mitems())))\n\u001b[1;32m    684\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m   \u001b[39mwith\u001b[39;00m CustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/sequential.py:437\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    435\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(name\u001b[39m=\u001b[39mname)\n\u001b[1;32m    436\u001b[0m \u001b[39mfor\u001b[39;00m layer_config \u001b[39min\u001b[39;00m layer_configs:\n\u001b[0;32m--> 437\u001b[0m   layer \u001b[39m=\u001b[39m layer_module\u001b[39m.\u001b[39;49mdeserialize(layer_config,\n\u001b[1;32m    438\u001b[0m                                    custom_objects\u001b[39m=\u001b[39;49mcustom_objects)\n\u001b[1;32m    439\u001b[0m   model\u001b[39m.\u001b[39madd(layer)\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39minputs \u001b[39mand\u001b[39;00m build_input_shape \u001b[39mand\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[39misinstance\u001b[39m(build_input_shape, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))):\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/layers/serialization.py:205\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m populate_deserializable_objects()\n\u001b[0;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m generic_utils\u001b[39m.\u001b[39;49mdeserialize_keras_object(\n\u001b[1;32m    206\u001b[0m     config,\n\u001b[1;32m    207\u001b[0m     module_objects\u001b[39m=\u001b[39;49mLOCAL\u001b[39m.\u001b[39;49mALL_OBJECTS,\n\u001b[1;32m    208\u001b[0m     custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    209\u001b[0m     printable_module_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlayer\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/utils/generic_utils.py:679\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    676\u001b[0m custom_objects \u001b[39m=\u001b[39m custom_objects \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcustom_objects\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m arg_spec\u001b[39m.\u001b[39margs:\n\u001b[0;32m--> 679\u001b[0m   deserialized_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[1;32m    680\u001b[0m       cls_config,\n\u001b[1;32m    681\u001b[0m       custom_objects\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m    682\u001b[0m           \u001b[39mlist\u001b[39;49m(_GLOBAL_CUSTOM_OBJECTS\u001b[39m.\u001b[39;49mitems()) \u001b[39m+\u001b[39;49m\n\u001b[1;32m    683\u001b[0m           \u001b[39mlist\u001b[39;49m(custom_objects\u001b[39m.\u001b[39;49mitems())))\n\u001b[1;32m    684\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m   \u001b[39mwith\u001b[39;00m CustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/training.py:2720\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2716\u001b[0m functional_model_keys \u001b[39m=\u001b[39m [\n\u001b[1;32m   2717\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlayers\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minput_layers\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moutput_layers\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2718\u001b[0m ]\n\u001b[1;32m   2719\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(key \u001b[39min\u001b[39;00m config \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m functional_model_keys):\n\u001b[0;32m-> 2720\u001b[0m   inputs, outputs, layers \u001b[39m=\u001b[39m functional\u001b[39m.\u001b[39;49mreconstruct_from_config(\n\u001b[1;32m   2721\u001b[0m       config, custom_objects)\n\u001b[1;32m   2722\u001b[0m   model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(inputs\u001b[39m=\u001b[39minputs, outputs\u001b[39m=\u001b[39moutputs, name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   2723\u001b[0m   functional\u001b[39m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/functional.py:1312\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39mwhile\u001b[39;00m layer_nodes:\n\u001b[1;32m   1311\u001b[0m   node_data \u001b[39m=\u001b[39m layer_nodes[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 1312\u001b[0m   \u001b[39mif\u001b[39;00m process_node(layer, node_data):\n\u001b[1;32m   1313\u001b[0m     layer_nodes\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n\u001b[1;32m   1314\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[39m# If a node can't be processed, stop processing the nodes of\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m     \u001b[39m# the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/functional.py:1256\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m layer\u001b[39m.\u001b[39m_preserve_input_structure_in_config:\n\u001b[1;32m   1254\u001b[0m   input_tensors \u001b[39m=\u001b[39m (\n\u001b[1;32m   1255\u001b[0m       base_layer_utils\u001b[39m.\u001b[39munnest_if_single_tensor(input_tensors))\n\u001b[0;32m-> 1256\u001b[0m output_tensors \u001b[39m=\u001b[39m layer(input_tensors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1258\u001b[0m \u001b[39m# Update node index map.\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m output_index \u001b[39m=\u001b[39m (tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(output_tensors)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m\n\u001b[1;32m   1260\u001b[0m                 _keras_history\u001b[39m.\u001b[39mnode_index)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/base_layer.py:944\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 944\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m    945\u001b[0m                                             input_list)\n\u001b[1;32m    947\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    948\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/base_layer.py:2315\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   2310\u001b[0m     training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[1;32m   2313\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[1;32m   2314\u001b[0m   \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 2315\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[1;32m   2316\u001b[0m       inputs, input_masks, args, kwargs)\n\u001b[1;32m   2318\u001b[0m   \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2320\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2321\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/base_layer.py:2186\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m   2184\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m   2185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/engine/base_layer.py:2232\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m   2230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m   2231\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m-> 2232\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2234\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m   2235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m   2236\u001b[0m                         build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py:250\u001b[0m, in \u001b[0;36mConv.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    248\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compiled_convolution_op(inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel)\n\u001b[1;32m    249\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvolution_op(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    253\u001b[0m   output_rank \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py:225\u001b[0m, in \u001b[0;36mConv.convolution_op\u001b[0;34m(self, inputs, kernel)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m   tf_padding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding\n\u001b[0;32m--> 225\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mconvolution(\n\u001b[1;32m    226\u001b[0m     inputs,\n\u001b[1;32m    227\u001b[0m     kernel,\n\u001b[1;32m    228\u001b[0m     strides\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrides),\n\u001b[1;32m    229\u001b[0m     padding\u001b[39m=\u001b[39;49mtf_padding,\n\u001b[1;32m    230\u001b[0m     dilations\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation_rate),\n\u001b[1;32m    231\u001b[0m     data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tf_data_format,\n\u001b[1;32m    232\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:1150\u001b[0m, in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnn.convolution\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   1141\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvolution_v2\u001b[39m(  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1148\u001b[0m     dilations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1150\u001b[0m   \u001b[39mreturn\u001b[39;00m convolution_internal(\n\u001b[1;32m   1151\u001b[0m       \u001b[39minput\u001b[39;49m,  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;49;00m\n\u001b[1;32m   1152\u001b[0m       filters,\n\u001b[1;32m   1153\u001b[0m       strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m   1154\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   1155\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[1;32m   1156\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[1;32m   1157\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:1282\u001b[0m, in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1279\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     op \u001b[39m=\u001b[39m conv1d\n\u001b[0;32m-> 1282\u001b[0m   \u001b[39mreturn\u001b[39;00m op(\n\u001b[1;32m   1283\u001b[0m       \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1284\u001b[0m       filters,\n\u001b[1;32m   1285\u001b[0m       strides,\n\u001b[1;32m   1286\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   1287\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[1;32m   1288\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[1;32m   1289\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1290\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1291\u001b[0m   \u001b[39mif\u001b[39;00m channel_index \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:2756\u001b[0m, in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2752\u001b[0m input_rank \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m   2753\u001b[0m \u001b[39mif\u001b[39;00m input_rank \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m input_rank \u001b[39m<\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m   2754\u001b[0m   \u001b[39m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[39;00m\n\u001b[1;32m   2755\u001b[0m   \u001b[39m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[39;00m\n\u001b[0;32m-> 2756\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39;49mconv2d(\n\u001b[1;32m   2757\u001b[0m       \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2758\u001b[0m       \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mfilters,\n\u001b[1;32m   2759\u001b[0m       strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m   2760\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2761\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[1;32m   2762\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[1;32m   2763\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   2764\u001b[0m \u001b[39mreturn\u001b[39;00m squeeze_batch_dims(\n\u001b[1;32m   2765\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m   2766\u001b[0m     functools\u001b[39m.\u001b[39mpartial(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2773\u001b[0m     inner_rank\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m   2774\u001b[0m     name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:969\u001b[0m, in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    965\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    966\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mExpected list for \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdilations\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    967\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv2d\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Op, not \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m dilations)\n\u001b[1;32m    968\u001b[0m dilations \u001b[39m=\u001b[39m [_execute\u001b[39m.\u001b[39mmake_int(_i, \u001b[39m\"\u001b[39m\u001b[39mdilations\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m dilations]\n\u001b[0;32m--> 969\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m    970\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mConv2D\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m, strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m    971\u001b[0m                 padding\u001b[39m=\u001b[39;49mpadding, use_cudnn_on_gpu\u001b[39m=\u001b[39;49muse_cudnn_on_gpu,\n\u001b[1;32m    972\u001b[0m                 explicit_paddings\u001b[39m=\u001b[39;49mexplicit_paddings,\n\u001b[1;32m    973\u001b[0m                 data_format\u001b[39m=\u001b[39;49mdata_format, dilations\u001b[39m=\u001b[39;49mdilations, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    974\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m    975\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:779\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m    778\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[0;32m--> 779\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    780\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    781\u001b[0m                            input_types)\n\u001b[1;32m    782\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    783\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    784\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:552\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    546\u001b[0m       values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    547\u001b[0m           values,\n\u001b[1;32m    548\u001b[0m           name\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mname,\n\u001b[1;32m    549\u001b[0m           as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref,\n\u001b[1;32m    550\u001b[0m           preferred_dtype\u001b[39m=\u001b[39mdefault_dtype)\n\u001b[1;32m    551\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[1;32m    553\u001b[0m         values,\n\u001b[1;32m    554\u001b[0m         name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    555\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    556\u001b[0m         as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref,\n\u001b[1;32m    557\u001b[0m         preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype)\n\u001b[1;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1640\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1631\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1632\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1633\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1637\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1639\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1640\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1642\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1643\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:2077\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 2077\u001b[0m   \u001b[39mreturn\u001b[39;00m var\u001b[39m.\u001b[39;49m_dense_var_to_tensor(dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1438\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1436\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_value()\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1438\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue()\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:582\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_value\n\u001b[1;32m    581\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mNone\u001b[39;00m, ignore_existing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 582\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:691\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    689\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle()\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle()\n\u001b[1;32m    693\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    694\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    695\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[1;32m    697\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[1;32m    698\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    699\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:681\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_and_set_handle\u001b[39m():\n\u001b[0;32m--> 681\u001b[0m   result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[1;32m    682\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[1;32m    683\u001b[0m   _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[1;32m    684\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:493\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m dtype \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 493\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m    494\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, resource\u001b[39m=\u001b[39;49mresource, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    495\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m    496\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:779\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m    778\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[0;32m--> 779\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    780\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    781\u001b[0m                            input_types)\n\u001b[1;32m    782\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    783\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    784\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:552\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    546\u001b[0m       values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    547\u001b[0m           values,\n\u001b[1;32m    548\u001b[0m           name\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mname,\n\u001b[1;32m    549\u001b[0m           as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref,\n\u001b[1;32m    550\u001b[0m           preferred_dtype\u001b[39m=\u001b[39mdefault_dtype)\n\u001b[1;32m    551\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[1;32m    553\u001b[0m         values,\n\u001b[1;32m    554\u001b[0m         name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    555\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    556\u001b[0m         as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref,\n\u001b[1;32m    557\u001b[0m         preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype)\n\u001b[1;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1595\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m graph\u001b[39m.\u001b[39mbuilding_function:\n\u001b[1;32m   1590\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1591\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1592\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mAttempting to capture an EagerTensor without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1593\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mbuilding a function.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1594\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m-> 1595\u001b[0m     \u001b[39mreturn\u001b[39;00m graph\u001b[39m.\u001b[39;49mcapture(value, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1597\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m   dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:730\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture_eager_tensor(tensor, name)\n\u001b[1;32m    729\u001b[0m   \u001b[39m# Large EagerTensors and resources are captured with Placeholder ops\u001b[39;00m\n\u001b[0;32m--> 730\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_helper(tensor, name, shape)\n\u001b[1;32m    731\u001b[0m \u001b[39mif\u001b[39;00m tensor\u001b[39m.\u001b[39mgraph \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m    732\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:765\u001b[0m, in \u001b[0;36mFuncGraph._capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    763\u001b[0m capture \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_captures\u001b[39m.\u001b[39mget(\u001b[39mid\u001b[39m(tensor))\n\u001b[1;32m    764\u001b[0m \u001b[39mif\u001b[39;00m capture \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 765\u001b[0m   placeholder \u001b[39m=\u001b[39m _create_substitute_placeholder(\n\u001b[1;32m    766\u001b[0m       tensor, name\u001b[39m=\u001b[39;49mname, dtype\u001b[39m=\u001b[39;49mtensor\u001b[39m.\u001b[39;49mdtype, shape\u001b[39m=\u001b[39;49mshape)\n\u001b[1;32m    767\u001b[0m   \u001b[39m# Record the composite device as an attribute to the placeholder.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m   \u001b[39m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[39;00m\n\u001b[1;32m    769\u001b[0m   \u001b[39m# Currently, a packed eager tensor is always placed on a CompositeDevice.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, ops\u001b[39m.\u001b[39mEagerTensor) \u001b[39mand\u001b[39;00m tensor\u001b[39m.\u001b[39mis_packed:\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1314\u001b[0m, in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1312\u001b[0m   shape \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1313\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1314\u001b[0m   placeholder \u001b[39m=\u001b[39m graph_placeholder(\n\u001b[1;32m   1315\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype \u001b[39mor\u001b[39;49;00m value\u001b[39m.\u001b[39;49mdtype, shape\u001b[39m=\u001b[39;49mshape, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1316\u001b[0m handle_data_util\u001b[39m.\u001b[39mcopy_handle_data(value, placeholder)\n\u001b[1;32m   1317\u001b[0m \u001b[39mreturn\u001b[39;00m placeholder\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/eager/graph_only_ops.py:34\u001b[0m, in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     32\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m     33\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m: shape}\n\u001b[0;32m---> 34\u001b[0m op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPlaceholder\u001b[39;49m\u001b[39m\"\u001b[39;49m, [], [dtype], input_types\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m     36\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m     37\u001b[0m result, \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m op_callbacks\u001b[39m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[1;32m     39\u001b[0m   \u001b[39m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[1;32m     40\u001b[0m   \u001b[39m# are unified. Remove this `if` block.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:694\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    692\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    693\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    695\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    696\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3754\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3751\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3752\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3753\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3754\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[1;32m   3755\u001b[0m       node_def,\n\u001b[1;32m   3756\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3757\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3758\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3759\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3760\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3761\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3762\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   3763\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3764\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2129\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2127\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2128\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[0;32m-> 2129\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[1;32m   2130\u001b[0m                             control_input_ops, op_def)\n\u001b[1;32m   2131\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[1;32m   2133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/GitHub/computer-vision-rps/myenv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1960\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1956\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[1;32m   1957\u001b[0m                                          serialized)\n\u001b[1;32m   1959\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1960\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[1;32m   1961\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1962\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random #for computer choice\n",
    "import cv2 #to leverage camera\n",
    "from keras.models import load_model #to run the  model\n",
    "import numpy as np #for arrays for interpretting the image\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class CvRps:\n",
    "\n",
    "    choice_list = ['rock', 'paper', 'scissors'] #declared this outside the init without self\n",
    "    start_time = time.time()\n",
    "    seconds = 7 #set how many seconds to run the camera \n",
    "\n",
    "\n",
    "    def __init__(self,rounds):\n",
    "        self.rounds = 1\n",
    "        self.computer_wins = 0\n",
    "        self.user_wins = 0\n",
    "\n",
    "\n",
    "    def get_prediction(self, rounds):        \n",
    "        \n",
    "        \n",
    "        while self.user_wins < 4 and self.computer_wins < 4:\n",
    "        \n",
    "\n",
    "            if self.user_wins ==3 or self.computer_wins == 3:\n",
    "                print(f\" GAME ENDING:.... user score: {self.user_wins} ||| Computer score: {self.computer_wins}\")\n",
    "                break\n",
    "            else: \n",
    "                print()\n",
    "                print(f'----------Round: {self.rounds}-------------')\n",
    "                self.rounds = self.rounds +1\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                print(f\"user score: {self.user_wins} ||| Computer score: {self.computer_wins}\")\n",
    "                model = load_model('keras_model2.h5')\n",
    "                cap = cv2.VideoCapture(0)\n",
    "                data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "                ret, frame = cap.read()\n",
    "                resized_frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "                image_np = np.array(resized_frame)\n",
    "                normalized_image = (image_np.astype(np.float32) / 127.0) - 1 # Normalize the image\n",
    "                data[0] = normalized_image\n",
    "                cv2.imshow('frame', frame)\n",
    "                print('Ok the camera is now on. Show me your choice')\n",
    "                prediction = model.predict(data)\n",
    "\n",
    "                print(f'the array from the prediction is: {prediction}') #test to see if the values are changing - REMOVE\n",
    "                current_time = time.time()\n",
    "                elapsed_time = current_time - CvRps.start_time\n",
    "                if elapsed_time > CvRps.seconds:\n",
    "                    self.stop_camera(cap)#call the method to stop the camera\n",
    "                    self.get_user_choice(prediction)#call the convert the array to a choice\n",
    "        \n",
    "        else: \n",
    "            print('hit the last else') \n",
    "                \n",
    "\n",
    "        \n",
    "    def stop_camera(self, cap):\n",
    "        print('...camera now stopping') #just a test - REMOVE \n",
    "        cap.release()# After the loop release the cap object\n",
    "        cv2.destroyAllWindows()# Destroy all the windows\n",
    "        print('...camera stopped') #just a test - REMOVE \n",
    "        pass   \n",
    "\n",
    "    def get_user_choice(self, prediction):\n",
    "        np.array(prediction) #convert to array\n",
    "        idx_max = prediction.argmax() #find the max value\n",
    "        choices = [\"rock\", \"paper\", \"scissors\", \"nothing\"]\n",
    "        user_camera_choice = choices[idx_max]\n",
    "        print(f'...You chose {user_camera_choice}')\n",
    "        self.get_computer_choice(user_camera_choice) \n",
    "\n",
    "    def get_computer_choice(self,user_choice):\n",
    "        computer_choice = random.choice(CvRps.choice_list)\n",
    "        print(f'...The computer chose {computer_choice}')\n",
    "        self.get_winner(user_choice, computer_choice)\n",
    "\n",
    "    def get_winner(self, user_choice, computer_choice):\n",
    "        print(f\"...You picked: {user_choice}. The computer picked {computer_choice}\") #just testing to see if it makes it here\n",
    "        print(f'...checking result:')\n",
    "        stars = '**********'\n",
    "        if computer_choice == user_choice:\n",
    "            print(f\"{stars} It's a draw! {stars}\")\n",
    "        elif computer_choice == 'rock' and user_choice == 'scissors':\n",
    "            self.computer_wins += 1\n",
    "            print(f'{stars} You lost {stars}')\n",
    "        elif computer_choice == 'rock' and user_choice == 'paper':\n",
    "            print(f'{stars} You won {stars} ')\n",
    "            self.user_wins += 1\n",
    "        elif computer_choice == 'paper' and user_choice == 'rock':\n",
    "            print(f'{stars} You lost {stars}')\n",
    "            self.computer_wins += 1\n",
    "        elif computer_choice == 'paper' and user_choice == 'scissors':\n",
    "            print(f'{stars} You won {stars} ')\n",
    "            self.user_wins += 1\n",
    "        elif computer_choice == 'scissors' and user_choice == 'rock':\n",
    "            print(f'{stars} You won {stars} ')\n",
    "            self.user_wins += 1\n",
    "        elif computer_choice == 'scissors' and user_choice == 'paper':\n",
    "            print(f'{stars} You lost {stars}')\n",
    "            self.computer_wins += 1\n",
    "        else:\n",
    "            print('No Result: Seems to be an error somewhere')\n",
    "\n",
    "def play_rps():\n",
    "    game = CvRps(3)\n",
    "    game.get_prediction(3)\n",
    "    print('game end')\n",
    "    print()\n",
    "    cv2.VideoCapture(0).release()# After the loop release the cap object\n",
    "    cv2.destroyAllWindows()# Destroy all the windows\n",
    "\n",
    "\n",
    "play_rps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Round: 1-------------\n",
      "user score: 0 ||| Computer score: 0\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 1s 938ms/step\n",
      "[[5.0708491e-07 9.9670249e-01 3.2966612e-03 4.0671151e-07]]\n",
      "...camera now stopping\n",
      "...camera stopped\n",
      "...You chose paper\n",
      "...The computer chose paper\n",
      "...You picked: paper. The computer picked paper\n",
      "...checking result:\n",
      "********** It's a draw! **********\n",
      "----------Round: 2-------------\n",
      "user score: 0 ||| Computer score: 0\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[[5.6689066e-07 9.9382520e-01 6.1736139e-03 6.2088452e-07]]\n",
      "...camera now stopping\n",
      "...camera stopped\n",
      "...You chose paper\n",
      "...The computer chose scissors\n",
      "...You picked: paper. The computer picked scissors\n",
      "...checking result:\n",
      "********** You lost **********\n",
      "----------Round: 3-------------\n",
      "user score: 0 ||| Computer score: 1\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[6.7342393e-07 9.9477130e-01 5.2274386e-03 5.5892946e-07]]\n",
      "...camera now stopping\n",
      "...camera stopped\n",
      "...You chose paper\n",
      "...The computer chose scissors\n",
      "...You picked: paper. The computer picked scissors\n",
      "...checking result:\n",
      "********** You lost **********\n",
      "----------Round: 4-------------\n",
      "user score: 0 ||| Computer score: 2\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Ok the camera is now on. Show me your choice\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[6.3209836e-07 9.9446362e-01 5.5352133e-03 4.9912285e-07]]\n",
      "...camera now stopping\n",
      "...camera stopped\n",
      "...You chose paper\n",
      "...The computer chose scissors\n",
      "...You picked: paper. The computer picked scissors\n",
      "...checking result:\n",
      "********** You lost **********\n",
      " GAME ENDING:.... user score: 0 ||| Computer score: 3\n",
      "game end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random #for computer choice\n",
    "import cv2 #to leverage camera\n",
    "from keras.models import load_model #to run the  model\n",
    "import numpy as np #for arrays for interpretting the image\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class CvRps:\n",
    "\n",
    "    choice_list = ['rock', 'paper', 'scissors'] #declared this outside the init without self\n",
    "    start_time = time.time()\n",
    "    seconds = 3 #set how many seconds to run the camera \n",
    "\n",
    "\n",
    "    def __init__(self,rounds):\n",
    "        self.rounds = 1\n",
    "        self.computer_wins = 0\n",
    "        self.user_wins = 0\n",
    "\n",
    "    def get_prediction(self, rounds):        \n",
    "        \n",
    "        \n",
    "        # while self.user_wins < 4 and self.computer_wins < 4:\n",
    "        while True:\n",
    "\n",
    "            if self.user_wins ==3 or self.computer_wins == 3:\n",
    "                print(f\" GAME ENDING:.... user score: {self.user_wins} ||| Computer score: {self.computer_wins}\")\n",
    "                break\n",
    "            else: \n",
    "                print(f'----------Round: {self.rounds}-------------')\n",
    "                self.rounds = self.rounds +1\n",
    "                pass \n",
    "            \n",
    "            print(f\"user score: {self.user_wins} ||| Computer score: {self.computer_wins}\")\n",
    "            model = load_model('keras_model.h5')\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "            ret, frame = cap.read()\n",
    "            resized_frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            image_np = np.array(resized_frame)\n",
    "            normalized_image = (image_np.astype(np.float32) / 127.0) - 1 # Normalize the image\n",
    "            data[0] = normalized_image\n",
    "            cv2.imshow('frame', frame)\n",
    "            print('Ok the camera is now on. Show me your choice')\n",
    "            prediction = model.predict(data)\n",
    "\n",
    "            print(prediction) #test to see if the values are changing - REMOVE\n",
    "\n",
    "            current_time = time.time()\n",
    "            elapsed_time = current_time - CvRps.start_time\n",
    "            if elapsed_time > CvRps.seconds:\n",
    "                self.stop_camera(cap)#call the method to stop the camera\n",
    "                self.get_user_choice(prediction)#call the convert the array to a choice\n",
    "        \n",
    "        else: \n",
    "            print('hit the last else') \n",
    "                \n",
    "\n",
    "        \n",
    "    def stop_camera(self, cap):\n",
    "        print('...camera now stopping') #just a test - REMOVE \n",
    "        cap.release()# After the loop release the cap object\n",
    "        cv2.destroyAllWindows()# Destroy all the windows\n",
    "        print('...camera stopped') #just a test - REMOVE \n",
    "        pass   \n",
    "\n",
    "    def get_user_choice(self, prediction):\n",
    "        np.array(prediction) #convert to array\n",
    "        # idx_max = prediction.argmax() #find the max value\n",
    "        idx_max = np.argmax(prediction[0])\n",
    "        choices = [\"rock\", \"paper\", \"scissors\", \"nothing\"]\n",
    "        user_camera_choice = choices[idx_max]\n",
    "        print(f'...You chose {user_camera_choice}')\n",
    "        self.get_computer_choice(user_camera_choice) \n",
    "\n",
    "    def get_computer_choice(self,user_choice):\n",
    "        computer_choice = random.choice(CvRps.choice_list)\n",
    "        print(f'...The computer chose {computer_choice}')\n",
    "        self.get_winner(user_choice, computer_choice)\n",
    "\n",
    "    def get_winner(self, user_choice, computer_choice):\n",
    "        print(f\"...You picked: {user_choice}. The computer picked {computer_choice}\") #just testing to see if it makes it here\n",
    "        print(f'...checking result:')\n",
    "        stars = '**********'\n",
    "        if computer_choice == user_choice:\n",
    "            print(f\"{stars} It's a draw! {stars}\")\n",
    "        elif computer_choice == 'rock' and user_choice == 'scissors':\n",
    "            self.computer_wins += 1\n",
    "            print(f'{stars} You lost {stars}')\n",
    "        elif computer_choice == 'rock' and user_choice == 'paper':\n",
    "            print(f'{stars} You won {stars} ')\n",
    "            self.user_wins += 1\n",
    "        elif computer_choice == 'paper' and user_choice == 'rock':\n",
    "            print(f'{stars} You lost {stars}')\n",
    "            self.computer_wins += 1\n",
    "        elif computer_choice == 'paper' and user_choice == 'scissors':\n",
    "            print(f'{stars} You won {stars} ')\n",
    "            self.user_wins += 1\n",
    "        elif computer_choice == 'scissors' and user_choice == 'rock':\n",
    "            print(f'{stars} You won {stars} ')\n",
    "            self.user_wins += 1\n",
    "        elif computer_choice == 'scissors' and user_choice == 'paper':\n",
    "            print(f'{stars} You lost {stars}')\n",
    "            self.computer_wins += 1\n",
    "        else:\n",
    "            print('No Result: Seems to be an error somewhere')\n",
    "\n",
    "def play_rps():\n",
    "    game = CvRps(3)\n",
    "    game.get_prediction(3)\n",
    "    print('game end')\n",
    "    print()\n",
    "    cv2.VideoCapture(0).release()# After the loop release the cap object\n",
    "    cv2.destroyAllWindows()# Destroy all the windows\n",
    "\n",
    "\n",
    "play_rps()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('myenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46df01c1277bbafd5d9ee5000047bc4fcd386374d4f032a794278b95e9894e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
